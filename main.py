#!/usr/bin/env python3
"""
æ™ºèƒ½å‘½ä»¤è¡ŒåŠ©æ‰‹ â€”â€” ä¸»ç¨‹åºå…¥å£
é›†æˆ LLM å¯¹è¯ã€ç³»ç»Ÿå‘½ä»¤æ‰§è¡Œã€æ–‡ä»¶åˆ†æç­‰åŠŸèƒ½ã€‚

åŠŸèƒ½åˆ—è¡¨ï¼š
  - æ™®é€šå¯¹è¯ï¼šç›´æ¥è¾“å…¥æ–‡æœ¬ä¸ LLM äº¤äº’
  - !ps        ï¼šæŸ¥çœ‹å¹¶åˆ†ææœ€å  CPU çš„è¿›ç¨‹
  - !ls [è·¯å¾„]  ï¼šåˆ—å‡ºç›®å½•å†…å®¹å¹¶è®© LLM è§£é‡Š
  - !analyze <æ–‡ä»¶> ï¼šè®© LLM åˆ†ææ–‡ä»¶å†…å®¹
  - !explain <ä»£ç > ï¼šè®© LLM è§£é‡Šä¸€æ®µä»£ç 
  - !history    ï¼šæŸ¥çœ‹å¯¹è¯å†å²
  - !save       ï¼šä¿å­˜å¯¹è¯å†å²åˆ°æ–‡ä»¶
  - !load       ï¼šä»æ–‡ä»¶åŠ è½½å¯¹è¯å†å²
  - !clear      ï¼šæ¸…ç©ºå¯¹è¯å†å²
  - !help       ï¼šæ˜¾ç¤ºå¸®åŠ©ä¿¡æ¯
  - !quit / !exitï¼šé€€å‡ºç¨‹åº

"""

import subprocess
import sys
import os
import json
import datetime

# å°†å½“å‰ç›®å½•åŠ å…¥æœç´¢è·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))
from llm_wrapper import LLMWrapper, logger

# ==================== é…ç½® ====================
# é¡¹ç›®æ ¹ç›®å½•ï¼ˆè‡ªåŠ¨æ£€æµ‹ï¼‰
PROJECT_DIR = os.path.dirname(os.path.abspath(__file__))
MODEL_PATH = os.path.join(PROJECT_DIR, "models", "qwen1_5-1_8b-chat-q4_k_m.gguf")
HISTORY_FILE = os.path.join(PROJECT_DIR, "chat_history.json")


# ==================== ç³»ç»Ÿå‘½ä»¤å¤„ç† ====================

def execute_system_command(cmd: str) -> str:
    """
    åœ¨æœ¬åœ° Linux ç³»ç»Ÿä¸Šæ‰§è¡Œå‘½ä»¤å¹¶æ•è·è¾“å‡ºã€‚

    å‚æ•°ï¼š
        cmd: è¦æ‰§è¡Œçš„ shell å‘½ä»¤

    è¿”å›ï¼š
        str: å‘½ä»¤çš„æ ‡å‡†è¾“å‡ºå†…å®¹ï¼Œå‡ºé”™æ—¶è¿”å›é”™è¯¯ä¿¡æ¯
    """
    try:
        result = subprocess.run(
            cmd,
            shell=True,
            capture_output=True,
            text=True,
            timeout=30  # æœ€å¤šç­‰å¾… 30 ç§’
        )
        output = result.stdout
        if result.stderr:
            output += "\n[æ ‡å‡†é”™è¯¯è¾“å‡º]:\n" + result.stderr
        return output.strip() if output.strip() else "(å‘½ä»¤æ— è¾“å‡º)"
    except subprocess.TimeoutExpired:
        return "âŒ å‘½ä»¤æ‰§è¡Œè¶…æ—¶ï¼ˆè¶…è¿‡ 30 ç§’ï¼‰"
    except Exception as e:
        return f"âŒ å‘½ä»¤æ‰§è¡Œå¤±è´¥: {e}"


def handle_ps_command(llm: LLMWrapper) -> str:
    """
    å¤„ç† !ps å‘½ä»¤ï¼šæ‰§è¡Œ ps aux å¹¶è®© LLM åˆ†æç»“æœã€‚
    """
    print("ğŸ“Š æ­£åœ¨è·å–è¿›ç¨‹ä¿¡æ¯...")
    output = execute_system_command("ps aux --sort=-%cpu | head -n 15")
    print(f"\n--- ps aux è¾“å‡º ---\n{output}\n-------------------\n")

    prompt = (
        f"ä»¥ä¸‹æ˜¯ Linux ç³»ç»Ÿ `ps aux --sort=-%cpu` å‘½ä»¤çš„è¾“å‡ºï¼ˆæŒ‰ CPU ä½¿ç”¨ç‡æ’åºï¼‰ï¼š\n\n"
        f"```\n{output}\n```\n\n"
        f"è¯·ç”¨ä¸­æ–‡å¸®æˆ‘åˆ†æï¼š\n"
        f"1. æœ€å  CPU çš„è¿›ç¨‹æ˜¯ä»€ä¹ˆï¼Ÿå®ƒåœ¨åšä»€ä¹ˆï¼Ÿ\n"
        f"2. æœ‰æ²¡æœ‰å¼‚å¸¸æˆ–å¯ç–‘çš„è¿›ç¨‹ï¼Ÿ\n"
        f"3. ç®€è¦æ€»ç»“ç³»ç»Ÿå½“å‰çš„èµ„æºä½¿ç”¨æƒ…å†µã€‚"
    )
    print("ğŸ¤– æ­£åœ¨åˆ†æ...\n")
    return llm.send_prompt(prompt)


def handle_ls_command(llm: LLMWrapper, path: str = ".") -> str:
    """
    å¤„ç† !ls å‘½ä»¤ï¼šåˆ—å‡ºç›®å½•å¹¶è®© LLM è§£é‡Šã€‚
    """
    print(f"ğŸ“ æ­£åœ¨åˆ—å‡ºç›®å½•: {path}")
    output = execute_system_command(f"ls -la {path}")
    print(f"\n--- ls -la {path} ---\n{output}\n---------------------\n")

    prompt = (
        f"ä»¥ä¸‹æ˜¯ `ls -la {path}` å‘½ä»¤çš„è¾“å‡ºï¼š\n\n"
        f"```\n{output}\n```\n\n"
        f"è¯·ç”¨ä¸­æ–‡ç®€è¦è§£é‡Šè¿™ä¸ªç›®å½•ä¸­æœ‰ä»€ä¹ˆå†…å®¹ï¼ŒåŒ…æ‹¬æ–‡ä»¶ç±»å‹å’Œæƒé™ã€‚"
    )
    print("ğŸ¤– æ­£åœ¨åˆ†æ...\n")
    return llm.send_prompt(prompt)


def handle_analyze_command(llm: LLMWrapper, filename: str) -> str:
    """
    å¤„ç† !analyze å‘½ä»¤ï¼šè¯»å–æ–‡ä»¶å†…å®¹å¹¶è®© LLM æ€»ç»“åˆ†æã€‚
    """
    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.isfile(filename):
        print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {filename}")
        return ""

    # è¯»å–æ–‡ä»¶å†…å®¹ï¼ˆé™åˆ¶å¤§å°ï¼Œé˜²æ­¢è¶…å‡ºä¸Šä¸‹æ–‡çª—å£ï¼‰
    try:
        with open(filename, "r", encoding="utf-8", errors="replace") as f:
            content = f.read(4096)  # æœ€å¤šè¯»å– 4KB
        if len(content) >= 4096:
            content += "\n\n... (æ–‡ä»¶å†…å®¹è¿‡é•¿ï¼Œå·²æˆªæ–­)"
    except Exception as e:
        print(f"âŒ è¯»å–æ–‡ä»¶å¤±è´¥: {e}")
        return ""

    print(f"ğŸ“„ å·²è¯»å–æ–‡ä»¶: {filename} ({len(content)} å­—ç¬¦)")

    prompt = (
        f"ä»¥ä¸‹æ˜¯æ–‡ä»¶ `{os.path.basename(filename)}` çš„å†…å®¹ï¼š\n\n"
        f"```\n{content}\n```\n\n"
        f"è¯·ç”¨ä¸­æ–‡ï¼š\n"
        f"1. æ€»ç»“è¿™ä¸ªæ–‡ä»¶çš„ä¸»è¦å†…å®¹å’Œç”¨é€”\n"
        f"2. æŒ‡å‡ºå…³é”®éƒ¨åˆ†æˆ–æ½œåœ¨é—®é¢˜\n"
        f"3. å¦‚æœæ˜¯ä»£ç ï¼Œè§£é‡Šå…¶åŠŸèƒ½é€»è¾‘"
    )
    print("ğŸ¤– æ­£åœ¨åˆ†æ...\n")
    return llm.send_prompt(prompt)


def handle_explain_command(llm: LLMWrapper, code_snippet: str) -> str:
    """
    å¤„ç† !explain å‘½ä»¤ï¼šè®© LLM è§£é‡Šä¸€æ®µä»£ç ã€‚
    """
    prompt = (
        f"è¯·ç”¨ä¸­æ–‡è§£é‡Šä»¥ä¸‹ä»£ç çš„åŠŸèƒ½ï¼š\n\n"
        f"```\n{code_snippet}\n```\n\n"
        f"åŒ…æ‹¬ï¼š\n"
        f"1. ä»£ç çš„æ•´ä½“åŠŸèƒ½\n"
        f"2. å…³é”®æ­¥éª¤çš„é€è¡Œè§£é‡Š\n"
        f"3. ä½¿ç”¨äº†å“ªäº›é‡è¦çš„ç¼–ç¨‹æ¦‚å¿µæˆ–åº“"
    )
    print("ğŸ¤– æ­£åœ¨è§£é‡Š...\n")
    return llm.send_prompt(prompt)


def handle_system_exec(llm: LLMWrapper, cmd: str) -> str:
    """
    å¤„ç† @system å‘½ä»¤ï¼šæ‰§è¡Œä»»æ„ç³»ç»Ÿå‘½ä»¤å¹¶è®© LLM è§£é‡Šç»“æœã€‚
    """
    print(f"âš™ï¸ æ­£åœ¨æ‰§è¡Œ: {cmd}")
    output = execute_system_command(cmd)
    print(f"\n--- å‘½ä»¤è¾“å‡º ---\n{output}\n----------------\n")

    prompt = (
        f"ä»¥ä¸‹æ˜¯ Linux å‘½ä»¤ `{cmd}` çš„æ‰§è¡Œç»“æœï¼š\n\n"
        f"```\n{output}\n```\n\n"
        f"è¯·ç”¨ä¸­æ–‡è§£é‡Šè¿™ä¸ªå‘½ä»¤çš„è¾“å‡ºå«ä¹‰ã€‚"
    )
    print("ğŸ¤– æ­£åœ¨åˆ†æ...\n")
    return llm.send_prompt(prompt)


# ==================== å¯¹è¯å†å²ç®¡ç† ====================

def save_history(llm: LLMWrapper, filepath: str = None):
    """ä¿å­˜å¯¹è¯å†å²åˆ° JSON æ–‡ä»¶ã€‚"""
    filepath = filepath or HISTORY_FILE
    data = {
        "saved_at": datetime.datetime.now().isoformat(),
        "messages": llm.conversation_history
    }
    try:
        with open(filepath, "w", encoding="utf-8") as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
        print(f"ğŸ’¾ å¯¹è¯å†å²å·²ä¿å­˜åˆ°: {filepath}")
    except Exception as e:
        print(f"âŒ ä¿å­˜å¤±è´¥: {e}")


def load_history(llm: LLMWrapper, filepath: str = None):
    """ä» JSON æ–‡ä»¶åŠ è½½å¯¹è¯å†å²ã€‚"""
    filepath = filepath or HISTORY_FILE
    if not os.path.isfile(filepath):
        print(f"âŒ å†å²æ–‡ä»¶ä¸å­˜åœ¨: {filepath}")
        return

    try:
        with open(filepath, "r", encoding="utf-8") as f:
            data = json.load(f)
        llm.conversation_history = data.get("messages", [])
        saved_at = data.get("saved_at", "æœªçŸ¥")
        count = len(llm.conversation_history)
        print(f"ğŸ“‚ å·²åŠ è½½ {count} æ¡å¯¹è¯è®°å½•ï¼ˆä¿å­˜äº {saved_at}ï¼‰")
    except Exception as e:
        print(f"âŒ åŠ è½½å¤±è´¥: {e}")


def show_history(llm: LLMWrapper):
    """æ˜¾ç¤ºå½“å‰å¯¹è¯å†å²æ‘˜è¦ã€‚"""
    if not llm.conversation_history:
        print("ğŸ“­ å¯¹è¯å†å²ä¸ºç©º")
        return

    print(f"\nğŸ“‹ å½“å‰å¯¹è¯å†å²ï¼ˆå…± {len(llm.conversation_history)} æ¡ï¼‰ï¼š")
    print("-" * 50)
    for i, msg in enumerate(llm.conversation_history, 1):
        role = "ğŸ‘¤ ç”¨æˆ·" if msg["role"] == "user" else "ğŸ¤– åŠ©æ‰‹"
        # åªæ˜¾ç¤ºå‰ 80 ä¸ªå­—ç¬¦
        content = msg["content"][:80]
        if len(msg["content"]) > 80:
            content += "..."
        print(f"  {i}. {role}: {content}")
    print("-" * 50)


# ==================== å¸®åŠ©ä¿¡æ¯ ====================

def show_help():
    """æ˜¾ç¤ºå¸®åŠ©ä¿¡æ¯ã€‚"""
    help_text = """
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘          ğŸ¤– æ™ºèƒ½å‘½ä»¤è¡ŒåŠ©æ‰‹ - ä½¿ç”¨å¸®åŠ©               â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘                                                      â•‘
â•‘  ğŸ’¬ æ™®é€šå¯¹è¯ï¼šç›´æ¥è¾“å…¥æ–‡å­—å³å¯ä¸ AI å¯¹è¯             â•‘
â•‘                                                      â•‘
â•‘  ğŸ“Œ ç³»ç»Ÿå‘½ä»¤ï¼ˆä»¥ ! å¼€å¤´ï¼‰ï¼š                          â•‘
â•‘    !ps             æŸ¥çœ‹å¹¶åˆ†æç³»ç»Ÿè¿›ç¨‹                 â•‘
â•‘    !ls [è·¯å¾„]      åˆ—å‡ºå¹¶åˆ†æç›®å½•å†…å®¹                 â•‘
â•‘    !analyze <æ–‡ä»¶> åˆ†ææ–‡ä»¶å†…å®¹                       â•‘
â•‘    !explain <ä»£ç > è§£é‡Šä»£ç ç‰‡æ®µ                       â•‘
â•‘    @system <å‘½ä»¤>  æ‰§è¡Œä»»æ„å‘½ä»¤å¹¶åˆ†æç»“æœ             â•‘
â•‘                                                      â•‘
â•‘  ğŸ“ å¯¹è¯ç®¡ç†ï¼š                                       â•‘
â•‘    !history        æŸ¥çœ‹å¯¹è¯å†å²                       â•‘
â•‘    !save           ä¿å­˜å¯¹è¯å†å²                       â•‘
â•‘    !load           åŠ è½½å¯¹è¯å†å²                       â•‘
â•‘    !clear          æ¸…ç©ºå¯¹è¯å†å²                       â•‘
â•‘                                                      â•‘
â•‘  ğŸ”§ å…¶ä»–ï¼š                                           â•‘
â•‘    !help           æ˜¾ç¤ºæ­¤å¸®åŠ©                         â•‘
â•‘    !quit / !exit   é€€å‡ºç¨‹åº                           â•‘
â•‘                                                      â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
"""
    print(help_text)


# ==================== æ¬¢è¿ä¿¡æ¯ ====================

def show_banner():
    """æ˜¾ç¤ºå¯åŠ¨æ¨ªå¹…ã€‚"""
    banner = """
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                                                      â•‘
â•‘    ğŸ¤–  ä¸ªäººæ™ºèƒ½å‘½ä»¤è¡ŒåŠ©æ‰‹  v1.0                      â•‘
â•‘    åŸºäº llama.cpp + Qwen1.5-1.8B-Chat                â•‘
â•‘    è¿è¡Œç¯å¢ƒ: OpenEuler 24.03 LTS                     â•‘
â•‘                                                      â•‘
â•‘    è¾“å…¥ !help æŸ¥çœ‹æ‰€æœ‰å¯ç”¨å‘½ä»¤                        â•‘
â•‘    è¾“å…¥ !quit é€€å‡ºç¨‹åº                                â•‘
â•‘                                                      â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
"""
    print(banner)


# ==================== ä¸»å¾ªç¯ ====================

def main():
    """ç¨‹åºä¸»å…¥å£ï¼šå¯åŠ¨ LLM å¹¶è¿›å…¥äº¤äº’å¼å¾ªç¯ã€‚"""

    show_banner()

    # åˆ›å»º LLM å°è£…å™¨
    llm = LLMWrapper(model_path=MODEL_PATH)

    # å¯åŠ¨ LLM æœåŠ¡å™¨
    if not llm.start():
        print("âŒ æ— æ³•å¯åŠ¨ LLM æœåŠ¡å™¨ï¼Œè¯·æ£€æŸ¥æ¨¡å‹æ–‡ä»¶è·¯å¾„å’Œ llama.cpp ç¼–è¯‘çŠ¶æ€ã€‚")
        sys.exit(1)

    # å°è¯•åŠ è½½å†å²å¯¹è¯è®°å½•ï¼ˆå®ç°"è®°å¿†"åŠŸèƒ½ï¼‰
    if os.path.isfile(HISTORY_FILE):
        load_history(llm)

    try:
        while True:
            try:
                # è·å–ç”¨æˆ·è¾“å…¥
                user_input = input("\nğŸ’¬ ä½ > ").strip()

                # å¿½ç•¥ç©ºè¾“å…¥
                if not user_input:
                    continue

                # ========== å¤„ç†ç‰¹æ®Šå‘½ä»¤ ==========

                # é€€å‡ºå‘½ä»¤
                if user_input.lower() in ("!quit", "!exit", "quit", "exit"):
                    print("\nğŸ‘‹ å†è§ï¼æ­£åœ¨ä¿å­˜å¯¹è¯å†å²...")
                    save_history(llm)
                    break

                # å¸®åŠ©
                elif user_input.lower() == "!help":
                    show_help()

                # è¿›ç¨‹åˆ†æ
                elif user_input.lower() == "!ps":
                    handle_ps_command(llm)

                # ç›®å½•åˆ—è¡¨
                elif user_input.lower().startswith("!ls"):
                    parts = user_input.split(maxsplit=1)
                    path = parts[1] if len(parts) > 1 else "."
                    handle_ls_command(llm, path)

                # æ–‡ä»¶åˆ†æ
                elif user_input.lower().startswith("!analyze"):
                    parts = user_input.split(maxsplit=1)
                    if len(parts) < 2:
                        print("ç”¨æ³•: !analyze <æ–‡ä»¶è·¯å¾„>")
                    else:
                        handle_analyze_command(llm, parts[1])

                # ä»£ç è§£é‡Š
                elif user_input.lower().startswith("!explain"):
                    parts = user_input.split(maxsplit=1)
                    if len(parts) < 2:
                        print("ç”¨æ³•: !explain <ä»£ç ç‰‡æ®µ>")
                    else:
                        handle_explain_command(llm, parts[1])

                # ä»»æ„ç³»ç»Ÿå‘½ä»¤
                elif user_input.startswith("@system"):
                    cmd = user_input[7:].strip()
                    if not cmd:
                        print("ç”¨æ³•: @system <å‘½ä»¤>")
                    else:
                        handle_system_exec(llm, cmd)

                # å¯¹è¯å†å²
                elif user_input.lower() == "!history":
                    show_history(llm)

                elif user_input.lower() == "!save":
                    save_history(llm)

                elif user_input.lower() == "!load":
                    load_history(llm)

                elif user_input.lower() == "!clear":
                    llm.clear_history()
                    print("ğŸ—‘ï¸ å¯¹è¯å†å²å·²æ¸…ç©º")

                # ========== æ™®é€šå¯¹è¯ ==========
                else:
                    print("\nğŸ¤– åŠ©æ‰‹:\n")
                    llm.send_prompt(user_input)

            except KeyboardInterrupt:
                print("\n\nâš ï¸ æ£€æµ‹åˆ° Ctrl+Cï¼Œè¾“å…¥ !quit é€€å‡ºç¨‹åº")
                continue

    finally:
        # ç¡®ä¿æœåŠ¡å™¨è¢«å…³é—­
        llm.close()
        print("âœ… ç¨‹åºå·²é€€å‡º")


if __name__ == "__main__":
    main()
